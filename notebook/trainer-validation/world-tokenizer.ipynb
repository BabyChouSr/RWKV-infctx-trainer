{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfCtx trainer + world tokenizer\n",
    "The trainer validation with the world otkenizer\n",
    "\n",
    "> This project assumes you have the rwkv-infctx conda env setup, and you are executing in that environment - see the main README.md for the conda env setup steps\n",
    ">\n",
    "> All training runs (except dryrun) is configured to log to weights and bias, comment out the logger in the config file if you want to avoid this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## Setup & Tokenizer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets setup the various directories\n",
    "!mkdir -p ../../model/\n",
    "!mkdir -p ../../datapath/\n",
    "!mkdir -p ../../checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 4245.25it/s]\n",
      "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 623.50it/s]\n",
      "Dataset parquet downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 72.09it/s]\n",
      "Map (num_proc=32):   2%|       | 16691/1000000 [00:12<11:28, 1427.63 examples/s]^C\n"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset\n",
    "!cd ../../RWKV-v4neo && python3 preload_datapath.py ../notebook/trainer-validation/config/baseline-dryrun-world.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer Code validation via dryrun\n",
    "\n",
    "The following dryrun, help do a basic check that the existing trainer code changes are valid across 2 * 2 data samples.\n",
    "\n",
    "If this check fail, its most probably a code / envrionment setup issue (no further checks needed)\n",
    "\n",
    "It does not log the run the W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets initialized the L6-D512 model with the init_model.py code\n",
    "!cd ../../RWKV-v4neo/ && python3 init_model.py --n_layer 6 --n_embd 512 --vocab_size world ../model/L6-D512-world-init.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate source code and env is working, by doing a short 2 sample dryrun\n",
    "!cd ../../RWKV-v4neo && python3 lightning_trainer.py fit -c ../notebook/trainer-validation/config/baseline-dryrun-world.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
