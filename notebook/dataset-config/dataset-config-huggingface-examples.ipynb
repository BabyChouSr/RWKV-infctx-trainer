{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using HF (Hugging Face) based datasets with infctx trainer\n",
    "\n",
    "The infctx trainer makes a huge shift towards a HF focus dataset parser, with several pros and cons. This note book aims to cover all the common use cases for dataset handling and processing, that is supported by this trainer code.\n",
    "\n",
    "As this guide is focused only on the dataset configuration option side of things. And all the examples here will not perform any real training / checkpointing of an output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial setup\n",
    "\n",
    "Before we go into the dataset setup, lets perform an initial setup for all the folders we need, and a small toy model which we would use throughout the various examples within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-04 11:23:28,641] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 512\n",
      "Output model path: ../model/L6-D512-neox-init.pth\n",
      "Vocab size: 50277\n",
      "---- ----- ----\n",
      "Model exists, skipping init_model\n",
      "[2023-08-04 11:23:31,917] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 512\n",
      "Output model path: ../model/L6-D512-world-init.pth\n",
      "Vocab size: 65529\n",
      "---- ----- ----\n",
      "Model exists, skipping init_model\n",
      "[2023-08-04 11:23:35,233] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 512\n",
      "Output model path: ../model/L6-D512-V20259-init.pth\n",
      "Vocab size: 20259\n",
      "---- ----- ----\n",
      "Model exists, skipping init_model\n"
     ]
    }
   ],
   "source": [
    "# Setup the folders we will need\n",
    "!mkdir -p ../../model/\n",
    "!mkdir -p ../../datapath/\n",
    "!mkdir -p ../../checkpoint/\n",
    "\n",
    "# Initialized a simple L6-D512 model, for both the v4 neox (50277) tokenizer\n",
    "!cd ../../RWKV-v4neo/ && python3 ./init_model.py --n_layer 6 --n_embd 512 --vocab_size neox --skip-if-exists ../model/L6-D512-neox-init.pth\n",
    "\n",
    "# and rwkv world (65529) tokenizers\n",
    "!cd ../../RWKV-v4neo/ && python3 ./init_model.py --n_layer 6 --n_embd 512 --vocab_size world --skip-if-exists ../model/L6-D512-world-init.pth\n",
    "\n",
    "# If you have a custom vocab size, you can indicate accordingly as well with an int\n",
    "!cd ../../RWKV-v4neo/ && python3 ./init_model.py --n_layer 6 --n_embd 512 --vocab_size 20259 --skip-if-exists ../model/L6-D512-V20259-init.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using a text dataset via Hugging Face\n",
    "\n",
    "The following is the `mini-enwiki.yaml` settings, for using a textual dataset via huggingface, with most of the comments removed\n",
    "\n",
    "```.yaml\n",
    "trainer:\n",
    "  max_steps: 10\n",
    "  target_batch_size: 32\n",
    "model:\n",
    "  load_model: ../model/L6-D512-neox-init.pth\n",
    "  ctx_len: 1024\n",
    "  lr_init: 3e-4\n",
    "  bptt_learning: true\n",
    "  bptt_learning_range: -1\n",
    "data:\n",
    "  data_path: ../datapath/enwiki_10k_neox_1024/\n",
    "\n",
    "  source: \"teven/enwiki_10k\"\n",
    "  # # Additional source dataset params, used to grab subsets of the dataset\n",
    "  # source_dataset_params:\n",
    "  #   language: en\n",
    "\n",
    "  tokenizer: neox\n",
    "  min_token_size: 64\n",
    "  max_token_size: -1\n",
    "  text_rechunk_size: 2048\n",
    "  text_rechunk_force: true\n",
    "  custom_text_key: 'text'\n",
    "  test_split: 0.01\n",
    "  test_split_shuffle: false\n",
    "```\n",
    "\n",
    "### Understanding the `data` config, for textual datasets\n",
    "\n",
    "Lets go through each of data parameter settings and what they mean...\n",
    "\n",
    "**data.data_path** \n",
    "This is where the HF datapath is saved, when used against existing HF data sources.\n",
    "\n",
    "**data.source** \n",
    "This can be configured either as a hugging face dataset (eg. `teven/enwiki_10k`) or if intended to be used with local files `text / json / csv / pandas` or their respective file paths (see the local file examples for more details) \n",
    "\n",
    "**data.source_dataset_params** \n",
    "Additional params to configure the huggingface `load_dataset` command. This is useful mostly for larger dataset which supports parameters, to filter out a subsets specifically (defaults to empty object)\n",
    "\n",
    "**data.tokenizer**\n",
    "The tokenizer to use for the dataset, use either `neox` or `world` for the respective RWKV models. For custom HF tokenizer refer to the custom tokenizer example. (defaults to neox)\n",
    "\n",
    "**data.min_token_size/max_token_size**\n",
    "Scans the given dataset, and skips datasamples that fail to meet the given criteria. This is mostly useful for filtering small low quality datasamples in large datasets, or large datasample beyond what you intend to support. (this is done before rechunking if enabled, defaults to -1 which support all)\n",
    "\n",
    "**data.text_rechunk_force** : Enable text rechunking, this means, all the filtered datasamples will be merged together, with a new line between them. Before being split again by the rechunk size. This is mostly useful for large corpus of raw text data, and is consistent with how existing foundation model are trained from raw text files. This also allows more efficient training process (tokens/second), as each datasample will have the exact same token count. (Disabled by default unless your source is literally a \".txt\" file)\n",
    "\n",
    "**data.text_rechunk_size** : Number of tokens each datasample should have after rechunking. Recommended sizes is the context size you intend the model to support (ie. 2048, 4096, etc)\n",
    "\n",
    "**data.custom_text_key** : For huggingface datasets (or json/csv) by default we would use the `text` collumn if its avaliable. However some dataset store their text in a different collumn (eg. `code`). This allow you to choose which collumn would you like to use the text from. Note for more complicated instruct/input/output examples, you will want to see the 'multi_column' guide/examples instead.\n",
    "\n",
    "### Optimizing the `model.bptt_*` mode according to your dataset config ....\n",
    "\n",
    "**model.load_model** \n",
    "This is the `model.pth` file you start the training process from. This can be an exisitng model you are finetuning from, or a new model that you initalized with `init_model.py` script.\n",
    "\n",
    "**model.ctx_len** \n",
    "This is the training context length used in the training process. For the infctx trainer, your data samples can be larger then the training context length. If so, the data sample is split into chunks accordingly, and trained in parts (with bptt_learning enabled, which it is by default)\n",
    "\n",
    "This is ultimately a tradeoff between VRAM usage vs GPU compute usage, while you can save VRAM usage, this comes an increased compute cost, as first few chunks will need to recalculated multiple times for each subsequent chunk. There are also been recorded minor loss learning penalty especially for small context sizes.\n",
    "\n",
    "As such it is always recommended to configure this to be as large as what can be supported by your GPU in the power of 2 (1024,2048,4096,...) with some healthy vram buffer for checkpoints and gradients, and up to your dataset sample size (as its pointless to go beyond that)\n",
    "\n",
    "Typically this is 4096, or 8192 for ML training GPUS (24GB vram and above). For consumer GPUS, anything less then 512 is not recommended, due to compounded loss learning penalty involved when used with large data samples.\n",
    "\n",
    "**model.bptt_learning**\n",
    "Enabled by default, this is the core feature of infctx trainer. If your training ctx length is equal to your dataset context length, you can disable bptt_learning for an insignificant speed boost (barely measurable).\n",
    "\n",
    "In most cases its better to just set bptt_learning_range to 1 instead of switching it off\n",
    "\n",
    "**model.bptt_learning_range**\n",
    "While the default setting of `bptt_learning: true` and `bptt_learning_range: -1` will work by default for all use cases.\n",
    "\n",
    "When training across multiple GPUs, `bptt_learning_range: -1` has a small performance penalty in which it needs to syncronize the \n",
    "\n",
    "### Download and preload the datapath from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-04 11:31:18,816] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Found cached dataset parquet (/home/picocreator/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1022.75it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset\n",
    "!cd ../../RWKV-v4neo && python3 preload_datapath.py ../notebook/dataset-config/mini-enwiki.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-04 11:27:20,394] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '../notebook/dataset-config/mini-enwiki.yaml'], args=['fit', '-c', '../notebook/dataset-config/mini-enwiki.yaml'].\n",
      "  rank_zero_warn(\n",
      "/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/fabric/utilities/seed.py:39: UserWarning: No seed found, seed set to 4139054562\n",
      "  rank_zero_warn(f\"No seed found, seed set to {seed}\")\n",
      "Global seed set to 4139054562\n",
      "[RWKV.model]: Preloading model from '../model/L6-D512-world-init.pth'\n",
      "Using /home/picocreator/.cache/torch_extensions/py311_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/picocreator/.cache/torch_extensions/py311_cu117/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "[RWKV.model]: Loading model weights ( L6-D512-V65529 )\n",
      "[RWKV.model]: Finished initial model load\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       32\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             1\n",
      "   - accumulate_grad_batches: 32\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "Found cached dataset parquet (/home/picocreator/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 57.47it/s]\n",
      "Map (num_proc=16):   0%|                       | 0/10000 [00:00<?, ? examples/s]^C\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 368, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/connection.py\", line 224, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/connection.py\", line 422, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/connection.py\", line 387, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/queues.py\", line 367, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Validate source code and env is working, by doing a short 2 sample dryrun\n",
    "!cd ../../RWKV-v4neo && python3 lightning_trainer.py fit -c ../notebook/dataset-config/mini-enwiki.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-infctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
