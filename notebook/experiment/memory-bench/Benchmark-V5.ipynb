{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Experimental Memory benchmarking\n",
    "\n",
    "The following is meant to observe the memory performance in a more verbose CSV logging mode, for the baseline raven models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets download the custom models\n",
    "!mkdir -p ../../../model/\n",
    "!cd ../../../model/ && wget -nc \"https://huggingface.co/picocreator/memory-size-experiment-for-rwkv/resolve/main/RWKV-v5-baseline/BaseV5-C-Tune4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../../model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B5 V5 benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-08 16:55:23,226] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 5 tokens : 100.0% similarity, with 5 matched token, and 0 token mismatch\n",
      "## Model validation for 10 tokens : 100.0% similarity, with 10 matched token, and 0 token mismatch\n",
      "## Model validation for 15 tokens : 100.0% similarity, with 15 matched token, and 0 token mismatch\n",
      "## Model validation for 20 tokens : 100.0% similarity, with 20 matched token, and 0 token mismatch\n",
      "## Model validation for 25 tokens : 100.0% similarity, with 25 matched token, and 0 token mismatch\n",
      "## Model validation for 30 tokens : 100.0% similarity, with 30 matched token, and 0 token mismatch\n",
      "## Model validation for 35 tokens : 100.0% similarity, with 35 matched token, and 0 token mismatch\n",
      "## Model validation for 40 tokens : 100.0% similarity, with 40 matched token, and 0 token mismatch\n",
      "## Model validation for 45 tokens : 100.0% similarity, with 45 matched token, and 0 token mismatch\n",
      "## Model validation for 50 tokens : 100.0% similarity, with 50 matched token, and 0 token mismatch\n",
      "## Model validation for 55 tokens : 100.0% similarity, with 55 matched token, and 0 token mismatch\n",
      "## Model validation for 60 tokens : 100.0% similarity, with 60 matched token, and 0 token mismatch\n",
      "## Model validation for 65 tokens : 100.0% similarity, with 65 matched token, and 0 token mismatch\n",
      "## Model validation for 70 tokens : 100.0% similarity, with 70 matched token, and 0 token mismatch\n",
      "## Model validation for 75 tokens : 100.0% similarity, with 75 matched token, and 0 token mismatch\n",
      "## Model validation for 80 tokens : 100.0% similarity, with 80 matched token, and 0 token mismatch\n",
      "## Model validation for 85 tokens : 100.0% similarity, with 85 matched token, and 0 token mismatch\n",
      "## Model validation for 90 tokens : 98.88888888888889% similarity, with 89 matched token, and 1 token mismatch\n",
      "## Model validation for 95 tokens : 100.0% similarity, with 95 matched token, and 0 token mismatch\n",
      "## Model validation for 100 tokens : 100.0% similarity, with 100 matched token, and 0 token mismatch\n",
      "## Model validation for 105 tokens : 100.0% similarity, with 105 matched token, and 0 token mismatch\n",
      "## Model validation for 110 tokens : 100.0% similarity, with 110 matched token, and 0 token mismatch\n",
      "## Model validation for 115 tokens : 100.0% similarity, with 115 matched token, and 0 token mismatch\n",
      "## Model validation for 120 tokens : 100.0% similarity, with 120 matched token, and 0 token mismatch\n",
      "## Model validation for 125 tokens : 100.0% similarity, with 125 matched token, and 0 token mismatch\n",
      "## Model validation for 130 tokens : 100.0% similarity, with 130 matched token, and 0 token mismatch\n",
      "## Model validation for 135 tokens : 100.0% similarity, with 135 matched token, and 0 token mismatch\n",
      "## Model validation for 140 tokens : 100.0% similarity, with 140 matched token, and 0 token mismatch\n",
      "## Model validation for 145 tokens : 100.0% similarity, with 145 matched token, and 0 token mismatch\n",
      "## Model validation for 150 tokens : 100.0% similarity, with 150 matched token, and 0 token mismatch\n",
      "## Model validation for 160 tokens : 100.0% similarity, with 160 matched token, and 0 token mismatch\n",
      "## Model validation for 170 tokens : 100.0% similarity, with 170 matched token, and 0 token mismatch\n",
      "## Model validation for 180 tokens : 100.0% similarity, with 180 matched token, and 0 token mismatch\n",
      "## Model validation for 190 tokens : 100.0% similarity, with 190 matched token, and 0 token mismatch\n",
      "## Model validation for 200 tokens : 100.0% similarity, with 200 matched token, and 0 token mismatch\n",
      "## Model validation for 210 tokens : 100.0% similarity, with 210 matched token, and 0 token mismatch\n",
      "## Model validation for 220 tokens : 100.0% similarity, with 220 matched token, and 0 token mismatch\n",
      "## Model validation for 230 tokens : 100.0% similarity, with 230 matched token, and 0 token mismatch\n",
      "## Model validation for 240 tokens : 100.0% similarity, with 240 matched token, and 0 token mismatch\n",
      "## Model validation for 250 tokens : 100.0% similarity, with 250 matched token, and 0 token mismatch\n",
      "## Model validation for 260 tokens : 100.0% similarity, with 260 matched token, and 0 token mismatch\n",
      "## Model validation for 270 tokens : 100.0% similarity, with 270 matched token, and 0 token mismatch\n",
      "## Model validation for 280 tokens : 100.0% similarity, with 280 matched token, and 0 token mismatch\n",
      "## Model validation for 290 tokens : 100.0% similarity, with 290 matched token, and 0 token mismatch\n",
      "## Model validation for 300 tokens : 99.66666666666667% similarity, with 299 matched token, and 1 token mismatch\n",
      "## Model validation for 325 tokens : 99.6923076923077% similarity, with 324 matched token, and 1 token mismatch\n",
      "## Model validation for 350 tokens : 99.71428571428571% similarity, with 349 matched token, and 1 token mismatch\n",
      "## Model validation for 375 tokens : 99.73333333333333% similarity, with 374 matched token, and 1 token mismatch\n",
      "## Model validation for 400 tokens : 99.75% similarity, with 399 matched token, and 1 token mismatch\n",
      "## Model validation for 425 tokens : 99.76470588235294% similarity, with 424 matched token, and 1 token mismatch\n",
      "## Model validation for 450 tokens : 99.77777777777777% similarity, with 449 matched token, and 1 token mismatch\n",
      "## Model validation for 475 tokens : 99.78947368421053% similarity, with 474 matched token, and 1 token mismatch\n",
      "## Model validation for 500 tokens : 99.8% similarity, with 499 matched token, and 1 token mismatch\n",
      "## Model validation for 525 tokens : 99.80952380952381% similarity, with 524 matched token, and 1 token mismatch\n",
      "## Model validation for 550 tokens : 99.81818181818181% similarity, with 549 matched token, and 1 token mismatch\n",
      "## Model validation for 575 tokens : 99.82608695652175% similarity, with 574 matched token, and 1 token mismatch\n",
      "## Model validation for 600 tokens : 99.83333333333333% similarity, with 599 matched token, and 1 token mismatch\n",
      "## Model validation for 625 tokens : 99.83999999999999% similarity, with 624 matched token, and 1 token mismatch\n",
      "## Model validation for 650 tokens : 99.84615384615385% similarity, with 649 matched token, and 1 token mismatch\n",
      "## Model validation for 675 tokens : 99.85185185185185% similarity, with 674 matched token, and 1 token mismatch\n",
      "## Model validation for 700 tokens : 99.85714285714286% similarity, with 699 matched token, and 1 token mismatch\n",
      "## Model validation for 750 tokens : 99.86666666666667% similarity, with 749 matched token, and 1 token mismatch\n",
      "## Model validation for 800 tokens : 99.875% similarity, with 799 matched token, and 1 token mismatch\n",
      "## Model validation for 850 tokens : 99.76470588235294% similarity, with 848 matched token, and 2 token mismatch\n",
      "## Model validation for 900 tokens : 99.66666666666667% similarity, with 897 matched token, and 3 token mismatch\n",
      "## Model validation for 950 tokens : 99.57894736842105% similarity, with 946 matched token, and 4 token mismatch\n",
      "## Model validation for 1000 tokens : 99.5% similarity, with 995 matched token, and 5 token mismatch\n",
      "## Finished baseline model to eval output predictive matching (aka 0 memory?), for 1000 tokens\n"
     ]
    }
   ],
   "source": [
    "# Memory benchmarking of the Echo-B-1B4-Tune3.pth\n",
    "!python3 ./memory_script/eval_v5_memory_guided.py \"../../../model/BaseV5-C-Tune4.pth\" \"./logs/BaseV5-C-Tune4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-08 22:50:46,033] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/notebook/experiment/memory-bench/./memory_script/eval_v5_memory_guided.py\", line 43, in <module>\n",
      "    model = SimpleRWKV(model_path, device=\"cuda\")\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/RWKV-v5/src/model.py\", line 1372, in __init__\n",
      "    self.model = RWKV(**model_config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/RWKV-v5/src/model.py\", line 673, in __init__\n",
      "    self.blocks = nn.ModuleList([\n",
      "                                ^\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/RWKV-v5/src/model.py\", line 674, in <listcomp>\n",
      "    Block(i, n_layer, n_embd, n_head, head_size, dropout, dim_att, dim_ffn) for i in range(n_layer)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/RWKV-v5/src/model.py\", line 454, in __init__\n",
      "    self.ffn = RWKV_ChannelMix(layer_id, n_layer, n_embd, dim_ffn)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/jit/_script.py\", line 292, in init_then_script\n",
      "    original_init(self, *args, **kwargs)\n",
      "  File \"/home/picocreator/rwkv-proj/picocreator-memory-experiment/RWKV-v5/src/model.py\", line 419, in __init__\n",
      "    self.key = nn.Linear(n_embd, dim_ffn, bias=False)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 101, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 107, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/init.py\", line 412, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Memory benchmarking of the Echo-B-1B4-Tune3.pth\n",
    "!python3 ./memory_script/eval_v5_memory_guided.py \"../../../model/BaseV5-C-Tune4.pth\" \"./logs/BaseV5-C-Tune4-4k.csv\" 1100 4000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-infctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
