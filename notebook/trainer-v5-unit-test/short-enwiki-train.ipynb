{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Enwiki Train\n",
    "\n",
    "Test that the model init code, runs without issues\n",
    "\n",
    "**L6-D512 model with**\n",
    "- Layer count: 6\n",
    "- Embed size: 512"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## Preparing the init model and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_WANDB: False\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /home/ubuntu/dev-infctx/notebook/trainer-v5-unit-test\n",
      "TRAINER_DIR: /home/ubuntu/dev-infctx/RWKV-v5\n",
      "PROJECT_DIR: /home/ubuntu/dev-infctx\n"
     ]
    }
   ],
   "source": [
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=False\n",
    "WANDB_PREFIX=\"infctx-v5-unit-test\"\n",
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets setup the various directories\n",
    "!mkdir -p \"{PROJECT_DIR}/model/\"\n",
    "!mkdir -p \"{PROJECT_DIR}/datapath/\"\n",
    "!mkdir -p \"{PROJECT_DIR}/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets initialized the L6-D512 model with the init_model.py code\n",
    "!cd \"{TRAINER_DIR}\" && python3 init_model.py \\\n",
    "    --n_layer 6 --n_embd 512 \\\n",
    "    --vocab_size world \\\n",
    "    --skip-if-exists --safe-init \\\n",
    "    ../model/L6-D512-world-init.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████| 424/424 [00:00<00:00, 2.81MB/s]\n",
      "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                             | 0.00/15.2M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  28%|█████▌              | 4.19M/15.2M [00:00<00:00, 13.4MB/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████| 15.2M/15.2M [00:00<00:00, 23.4MB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1572.08it/s]\n",
      "Setting num_proc from 32 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 100%|███| 10000/10000 [00:00<00:00, 68642.50 examples/s]\n",
      "Map (num_proc=32): 100%|█████████| 10000/10000 [00:09<00:00, 1095.56 examples/s]\n",
      "Filter (num_proc=32): 100%|██████| 10000/10000 [00:07<00:00, 1428.02 examples/s]\n",
      "Map (num_proc=32): 100%|████████████| 1339/1339 [00:04<00:00, 285.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█| 751/751 [00:00<00:00, 26288.79 examples\n",
      "Saving the dataset (1/1 shards): 100%|███| 8/8 [00:00<00:00, 3017.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preload the dataset\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/config/enwiki_10k-world-4096.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-27 10:00:29,295] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n"
     ]
    }
   ],
   "source": [
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_10k-world-4096.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} (train-ctx=4096, data-ctx=4096, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\" \\\n",
    "        --model.load_model=\"../model/L6-D512-world-init.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
