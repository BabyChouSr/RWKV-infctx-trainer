{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort ( based on content length ), Offset and length\n",
    "\n",
    "Advance dataset operations, of sorting, offset, and length support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_WANDB: False\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /home/ubuntu/picocreator-memory-experiment/notebook/trainer-v5-validation\n",
      "TRAINER_DIR: /home/ubuntu/picocreator-memory-experiment/RWKV-v5\n",
      "PROJECT_DIR: /home/ubuntu/picocreator-memory-experiment\n"
     ]
    }
   ],
   "source": [
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"infctx-v5-sort-offset-test\"\n",
    "\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 20:25:28,862] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 2048\n",
      "Output model path: ../model/L6-D2048-neox-v5base-init.pth\n",
      "Vocab size: 50277\n",
      "Emb scale: 0.0001\n",
      "Note: this process takes a significant time (and ram) for large models\n",
      "---- ----- ----\n",
      "50277 2048  -0.0001 emb.weight\n",
      "2048  2048  1.0  blocks.0.att.gate.weight\n",
      "2048  2048  1.0  blocks.0.att.receptance.weight\n",
      "2048  2048  1.0  blocks.0.att.key.weight\n",
      "2048  2048  1.0  blocks.0.att.value.weight\n",
      "2048  2048  0    blocks.0.att.output.weight\n",
      "7168  2048  1.0  blocks.0.ffn.key.weight\n",
      "2048  2048  0    blocks.0.ffn.receptance.weight\n",
      "2048  7168  0    blocks.0.ffn.value.weight\n",
      "2048  2048  1.0  blocks.1.att.gate.weight\n",
      "2048  2048  1.0  blocks.1.att.receptance.weight\n",
      "2048  2048  1.0  blocks.1.att.key.weight\n",
      "2048  2048  1.0  blocks.1.att.value.weight\n",
      "2048  2048  0    blocks.1.att.output.weight\n",
      "7168  2048  1.0  blocks.1.ffn.key.weight\n",
      "2048  2048  0    blocks.1.ffn.receptance.weight\n",
      "2048  7168  0    blocks.1.ffn.value.weight\n",
      "2048  2048  1.0  blocks.2.att.gate.weight\n",
      "2048  2048  1.0  blocks.2.att.receptance.weight\n",
      "2048  2048  1.0  blocks.2.att.key.weight\n",
      "2048  2048  1.0  blocks.2.att.value.weight\n",
      "2048  2048  0    blocks.2.att.output.weight\n",
      "7168  2048  1.0  blocks.2.ffn.key.weight\n",
      "2048  2048  0    blocks.2.ffn.receptance.weight\n",
      "2048  7168  0    blocks.2.ffn.value.weight\n",
      "2048  2048  1.0  blocks.3.att.gate.weight\n",
      "2048  2048  1.0  blocks.3.att.receptance.weight\n",
      "2048  2048  1.0  blocks.3.att.key.weight\n",
      "2048  2048  1.0  blocks.3.att.value.weight\n",
      "2048  2048  0    blocks.3.att.output.weight\n",
      "7168  2048  1.0  blocks.3.ffn.key.weight\n",
      "2048  2048  0    blocks.3.ffn.receptance.weight\n",
      "2048  7168  0    blocks.3.ffn.value.weight\n",
      "2048  2048  1.0  blocks.4.att.gate.weight\n",
      "2048  2048  1.0  blocks.4.att.receptance.weight\n",
      "2048  2048  1.0  blocks.4.att.key.weight\n",
      "2048  2048  1.0  blocks.4.att.value.weight\n",
      "2048  2048  0    blocks.4.att.output.weight\n",
      "7168  2048  1.0  blocks.4.ffn.key.weight\n",
      "2048  2048  0    blocks.4.ffn.receptance.weight\n",
      "2048  7168  0    blocks.4.ffn.value.weight\n",
      "2048  2048  1.0  blocks.5.att.gate.weight\n",
      "2048  2048  1.0  blocks.5.att.receptance.weight\n",
      "2048  2048  1.0  blocks.5.att.key.weight\n",
      "2048  2048  1.0  blocks.5.att.value.weight\n",
      "2048  2048  0    blocks.5.att.output.weight\n",
      "7168  2048  1.0  blocks.5.ffn.key.weight\n",
      "2048  2048  0    blocks.5.ffn.receptance.weight\n",
      "2048  7168  0    blocks.5.ffn.value.weight\n",
      "50277 2048  0.5  head.weight\n"
     ]
    }
   ],
   "source": [
    "# Init the model\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 ./init_model.py \\\n",
    "        --n_layer 6 --n_embd 2048 \\\n",
    "        --vocab_size neox --skip-if-exists \\\n",
    "        \"../model/L6-D2048-neox-v5base-init.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map (num_proc=32): 100%|██████████| 10000/10000 [00:16<00:00, 598.58 examples/s]\n",
      "Filter (num_proc=32): 100%|██████| 10000/10000 [00:06<00:00, 1465.96 examples/s]\n",
      "Map: 100%|█████████████████████████| 9892/9892 [00:03<00:00, 2600.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█| 989/989 [00:00<00:00, 94373.03 examples\n",
      "Saving the dataset (1/1 shards): 100%|█| 100/100 [00:00<00:00, 11746.78 examples\n"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset \n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/config/test-sort-offset-length.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 20:46:09,675] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/ubuntu/picocreator-memory-experiment/notebook/trainer-v5-validation/config/test-sort-offset-length.yaml', '--trainer.logger.init_args.name=infctx-v5-sort-offset-test (deepspeed_stage_2_offload)', '--trainer.strategy=deepspeed_stage_2_offload', '--trainer.devices=auto'], args=['fit', '-c', '/home/ubuntu/picocreator-memory-experiment/notebook/trainer-v5-validation/config/test-sort-offset-length.yaml', '--trainer.logger.init_args.name=infctx-v5-sort-offset-test (deepspeed_stage_2_offload)', '--trainer.strategy=deepspeed_stage_2_offload', '--trainer.devices=auto'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 3941088705\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             1\n",
      "   - accumulate_grad_batches: 16\n",
      "   - effective_batch_size:    16\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|█| 989/989 [00:00<00:00, 75657.81 examples\n",
      "Saving the dataset (1/1 shards): 100%|█| 100/100 [00:00<00:00, 10710.41 examples\n",
      "[rank: 0] Global seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[2023-09-12 20:46:17,787] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Enabling DeepSpeed BF16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  6.000e-04 (0.0006)\n",
      "    - lr_final: 4.000e-04 (0.0004)\n",
      "\n",
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.434016704559326 seconds\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Rank: 0 partition count [1, 1] and sizes[(533245952, False), (384, False)] \n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 102 M \n",
      "1 | blocks | ModuleList | 327 M \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 102 M \n",
      "--------------------------------------\n",
      "533 M     Trainable params\n",
      "0         Non-trainable params\n",
      "533 M     Total params\n",
      "2,132.985 Total estimated model params size (MB)\n",
      "Epoch 0: 100%|██| 989/989 [04:38<00:00,  3.55it/s, v_num=5vi3, train/loss=8.380]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:30,  3.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 2/100 [00:00<00:28,  3.41it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 3/100 [00:01<00:51,  1.88it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 4/100 [00:01<00:44,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 5/100 [00:02<00:53,  1.76it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                 | 6/100 [00:03<00:48,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▎                | 7/100 [00:05<01:07,  1.38it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍                | 8/100 [00:05<01:01,  1.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 9/100 [00:06<01:02,  1.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 10/100 [00:06<00:58,  1.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 11/100 [00:06<00:54,  1.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 12/100 [00:07<00:51,  1.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 13/100 [00:07<00:48,  1.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 14/100 [00:07<00:48,  1.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 15/100 [00:08<00:45,  1.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 16/100 [00:09<00:47,  1.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 17/100 [00:09<00:45,  1.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 18/100 [00:09<00:43,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 19/100 [00:09<00:42,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 20/100 [00:10<00:40,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 21/100 [00:10<00:39,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 22/100 [00:12<00:42,  1.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 23/100 [00:12<00:41,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 24/100 [00:12<00:39,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 25/100 [00:15<00:45,  1.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 26/100 [00:15<00:43,  1.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 27/100 [00:15<00:42,  1.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 28/100 [00:15<00:41,  1.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 29/100 [00:16<00:39,  1.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 30/100 [00:16<00:38,  1.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:16<00:37,  1.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 32/100 [00:17<00:36,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:17<00:35,  1.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 34/100 [00:17<00:34,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:17<00:33,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 36/100 [00:18<00:32,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:19<00:32,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 38/100 [00:19<00:31,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:20<00:31,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 40/100 [00:20<00:30,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:20<00:30,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 42/100 [00:21<00:29,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:21<00:28,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 44/100 [00:22<00:28,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:22<00:27,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▊         | 46/100 [00:22<00:26,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:22<00:25,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 48/100 [00:23<00:25,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:23<00:24,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████▌        | 50/100 [00:23<00:23,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:24<00:23,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 52/100 [00:24<00:22,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|█████████        | 53/100 [00:24<00:21,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▏       | 54/100 [00:25<00:21,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:25<00:20,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████▌       | 56/100 [00:27<00:21,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:27<00:20,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▊       | 58/100 [00:27<00:20,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|██████████       | 59/100 [00:27<00:19,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▏      | 60/100 [00:28<00:18,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:28<00:18,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████████▌      | 62/100 [00:28<00:17,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:29<00:17,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▉      | 64/100 [00:29<00:16,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 65/100 [00:29<00:15,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|███████████▏     | 66/100 [00:30<00:15,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:30<00:14,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|███████████▌     | 68/100 [00:31<00:14,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:31<00:14,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▉     | 70/100 [00:32<00:13,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████     | 71/100 [00:32<00:13,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|████████████▏    | 72/100 [00:32<00:12,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:32<00:12,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 74/100 [00:33<00:11,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:33<00:11,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▉    | 76/100 [00:33<00:10,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:34<00:10,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 78/100 [00:34<00:09,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:34<00:09,  2.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|█████████████▌   | 80/100 [00:35<00:08,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:35<00:08,  2.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▉   | 82/100 [00:35<00:07,  2.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:35<00:07,  2.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████████▎  | 84/100 [00:36<00:06,  2.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:36<00:06,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|██████████████▌  | 86/100 [00:36<00:05,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:37<00:05,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████▉  | 88/100 [00:37<00:05,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:37<00:04,  2.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████████▎ | 90/100 [00:38<00:04,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:38<00:03,  2.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████████▋ | 92/100 [00:39<00:03,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:39<00:02,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████▉ | 94/100 [00:39<00:02,  2.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:39<00:02,  2.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 96/100 [00:40<00:01,  2.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:40<00:01,  2.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████████▋| 98/100 [00:40<00:00,  2.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:40<00:00,  2.42it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 989/989 [05:20<00:00,  3.08it/s, v_num=5vi3, train/loss=8.380, \u001b[A\n",
      "Epoch 0: 100%|█| 989/989 [05:20<00:00,  3.08it/s, v_num=5vi3, train/loss=8.380, `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 989/989 [05:20<00:00,  3.08it/s, v_num=5vi3, train/loss=8.380, \n"
     ]
    }
   ],
   "source": [
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/test-sort-offset-length.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} (deepspeed_stage_2_offload)\" \\\n",
    "        --trainer.strategy=\"deepspeed_stage_2_offload\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-infctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
